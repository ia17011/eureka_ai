{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k1r0hi/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'p_noun_fkzw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2e153685bec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#単語のリスト\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p_noun_fkzw.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfkzw_nouns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mfkzw_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfkzw_nouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfkzw_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfkzw_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'p_noun_fkzw.csv'"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "import csv\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim import corpora\n",
    "from gensim import matutils\n",
    "\n",
    "#多クラス分類(現状２つしかない)\n",
    "#ランダムフォレストを使っている\n",
    "\n",
    "#単語のリスト\n",
    "word_list = []\n",
    "with open('p_noun_fkzw.csv','r') as fkzw_nouns:\n",
    "    fkzw_reader = csv.reader(fkzw_nouns)\n",
    "    for fkzw_word in fkzw_reader:\n",
    "        word_list.append(fkzw_word)\n",
    "\n",
    "with open('p_noun_ntm.csv','r') as ntm_nouns:\n",
    "    ntm_reader = csv.reader(ntm_nouns)\n",
    "    for ntm_word in ntm_reader:\n",
    "        word_list.append(ntm_word)\n",
    "#print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#単語のリストから辞書を作っている\n",
    "dictionary = corpora.Dictionary(word_list)\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#高頻度なものを消す\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.1)\n",
    "#dictionary.save_as_text('fkzwdic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#福沢(fkzw)と夏目(ntm)の名詞リスト\n",
    "fkzw_words = word_list[0]\n",
    "ntm_words = word_list[1]\n",
    "#print(words)\n",
    "\n",
    "#BoW\n",
    "#doc2bowは、doc2bow()はdistinctした結果から単語の出現回数を数える。\n",
    "fkzw_vec = dictionary.doc2bow(fkzw_words)\n",
    "ntm_vec = dictionary.doc2bow(ntm_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7a155a276f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfkzw_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mntm_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfkzw_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfkzw_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "fkzw_words = word_list[0]\n",
    "ntm_words = word_list[1]\n",
    "\n",
    "\n",
    "fkzw_tmp = dictionary.doc2bow(fkzw_words)\n",
    "fkzw_dense = list(matutils.corpus2dense([fkzw_tmp], num_terms=len(dictionary)).T[0])\n",
    "\n",
    "ntm_tmp = dictionary.doc2bow(ntm_words)\n",
    "ntm_dense = list(matutils.corpus2dense([ntm_tmp], num_terms=len(dictionary)).T[0])\n",
    "\n",
    "#福沢の辞書内のすべてのIDと頻度のリストを表示\n",
    "#print(fkzw_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=777, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#print(dense)\n",
    "data_train = []\n",
    "data_train.append(fkzw_dense)\n",
    "data_train.append(ntm_dense)\n",
    "\n",
    "label_train = [1, 0] #1: fkzw, 0: ntm\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "#estimator = RandomForestClassifier(random_state=777)\n",
    "\n",
    "#学習\n",
    "estimator.fit(data_train, label_train)\n",
    "\n",
    "\n",
    "#print(\"==== 学習データと予測データが一緒の場合\")\n",
    "#print(estimator.score(data_train, label_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "label_predict = estimator.predict(data_train)\n",
    "print(label_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data_train_s, data_test_s, label_train_s, label_test_s = train_test_split(data_train, label_train, test_size=0.4)\n",
    "\n",
    "# 学習用に切り出したやつだけで学習\n",
    "estimator.fit(data_train_s, label_train_s)\n",
    "\n",
    "# 予測。正解が分かってる場合は、predict関数じゃなくてこうやると、正解率出してくれる\n",
    "print(estimator.score(data_test_s, label_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
